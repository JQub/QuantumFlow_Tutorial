{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to build the h-net\n",
    "## Prepare environment and  define parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_colab = True\n",
    "import sys\n",
    "if is_colab:\n",
    "    !pip install -q torch==1.9.0\n",
    "    !pip install -q torchvision==0.10.0\n",
    "    !pip install -q qiskit==0.20.0\n",
    "    !pip install qfnn\n",
    "    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w9VRv0iVfsH20Kb_MkF3yFhFeiYDVy5n' -O model.tar.gz\n",
    "    !tar zxvf /content/model.tar.gz\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import qiskit\n",
    "from qiskit import  QuantumCircuit, ClassicalRegister\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "\n",
    "from qfnn.qf_fb.q_output import fire_ibmq,analyze,add_measure\n",
    "from qfnn.qf_circ.n_lyr_circ import N_LYR_Circ\n",
    "from qfnn.qf_circ.u_lyr_circ import U_LYR_Circ\n",
    "from qfnn.qf_circ.p_lyr_circ import P_LYR_Circ\n",
    "from qfnn.qf_fb.c_input import load_data,to_quantum_matrix\n",
    "from qfnn.qf_net.utils import binarize\n",
    "from qfnn.qf_fb.c_qf_mixer import Net\n",
    "from qfnn.qf_fb.c_input import ToQuantumData\n",
    "print = functools.partial(print, flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "### Input data preparation\n",
    "\n",
    "In this example, we will use MNIST dataset for demonstrating how the neural network\n",
    "runs on a quantum circuit.\n",
    "\n",
    "So, the first step is to load data from the MNIST. There are serveral points to be\n",
    " noted.\n",
    "\n",
    "* The model trained for demonstration is based on the subset of MNSIT with digits 3 and 6.\n",
    "* The input is down sampled to 4 by 4 to be executed on 4 qubits (which has 2^4=16 states)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "batch_size = 32\n",
    "inference_batch_size = 1\n",
    "\n",
    "if is_colab:\n",
    "    data_path = '/content/data' #mnist  path\n",
    "else:\n",
    "    data_path = 'Your path for data' #mnist  path\n",
    "\n",
    "train_loader, test_loader = load_data(interest_num,data_path,False,img_size,batch_size,inference_batch_size,False)\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix = to_quantum_matrix(data)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load model\n",
    "\n",
    "We have trained the neural network model. Here, we need to extract the data from the\n",
    "model to the local variables, which will be used for building the quantum circuit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if is_colab:\n",
    "    resume_path = '/content/model/u2_p2/model_best.tar' #model path\n",
    "else:\n",
    "    resume_path = 'Your path for model' #model path\n",
    "\n",
    "checkpoint = torch.load(resume_path, map_location='cpu')\n",
    "print(checkpoint['state_dict']['fc0.weight'])\n",
    "print(checkpoint['state_dict']['fc1.weight'])\n",
    "# print(checkpoint['state_dict']['fc2.batch.x_l_0_5'])\n",
    "# print(checkpoint['state_dict']['fc2.batch.x_g_0_5'])\n",
    "\n",
    "weight_1 = checkpoint['state_dict']['fc0.weight']\n",
    "weight_2 = checkpoint['state_dict']['fc1.weight']\n",
    "# norm_flag = checkpoint['state_dict']['fc2.batch.x_l_0_5']\n",
    "# norm_para = checkpoint['state_dict']['fc2.batch.x_running_rot']\n",
    "# print(norm_para)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the QF-pNet network\n",
    "\n",
    "In the following cell, we build the first layer of the QF-hNet using the qfnn library.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Generate the circuit of u-layer\n",
    "######################################################\n",
    "#create circuit\n",
    "circuit = QuantumCircuit()\n",
    "\n",
    "#init circuit, which is corresponding to a neuron with 4 qubits and 2 outputs\n",
    "u_layer = U_LYR_Circ(4,2)\n",
    "\n",
    "#create qubits to be invovled\n",
    "inps = u_layer.add_input_qubits(circuit)\n",
    "aux =u_layer.add_aux(circuit)\n",
    "u_layer_out_qubits = u_layer.add_out_qubits(circuit)\n",
    "\n",
    "#add u-layer to your circuit\n",
    "u_layer.forward(circuit,binarize(weight_1) ,inps,u_layer_out_qubits,quantum_matrix,aux)\n",
    "\n",
    "#show your circuit\n",
    "circuit.barrier()\n",
    "circuit.draw('text',fold=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we have a one-layer neural network with U-LYR. In the next step, we will on top\n",
    "of this layer to add an output layer, which is based on P-LYR, to the built\n",
    "quantum circuit of QF-hN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add p-layer to your circuit\n",
    "p_layer = P_LYR_Circ(2,2)\n",
    "p_aux = p_layer.add_aux(circuit,\"p_aux\")\n",
    "p_layer_output = p_layer.add_out_qubits(circuit)\n",
    "p_layer.forward(circuit,binarize(weight_2),u_layer_out_qubits,p_layer_output,p_aux)\n",
    "\n",
    "# #add n-layer to your circuit\n",
    "# norm = N_LYR_Circ(2)\n",
    "# norm_qubit = norm.add_norm_qubits(circuit)\n",
    "# norm_output_qubit = norm.add_out_qubits(circuit)\n",
    "# norm.forward(circuit,p_layer_output,norm_qubit,norm_output_qubit,norm_flag,norm_para)\n",
    "\n",
    "#add measurement to your circuit\n",
    "add_measure(circuit,p_layer_output,'reg')\n",
    "\n",
    "print(\"Output layer created!\")\n",
    "\n",
    "circuit.draw('text',fold =300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantum simulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum simulation\n",
    "######################################################\n",
    "\n",
    "qc_shots=8192\n",
    "opt_counts = fire_ibmq(circuit,qc_shots,True)\n",
    "(opt_mycount,bits) = analyze(opt_counts)\n",
    "opt_class_prob=[]\n",
    "for b in range(bits):\n",
    "    opt_class_prob.append(float(opt_mycount[b])/qc_shots)\n",
    "\n",
    "\n",
    "print(\"Simulation Result :\",opt_class_prob)\n",
    "print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\n",
    "print(\"Target class: {}\".format(target[0]))\n",
    "if opt_class_prob.index(max(opt_class_prob))==target[0]:\n",
    "    print(\"Correct prediction\")\n",
    "else:\n",
    "    print(\"Incorrect prediction\")\n",
    "print(\"=\"*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### classical inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "neural_in_layers = 'u:2,p:2'\n",
    "layers = []\n",
    "for item1 in neural_in_layers.split(\",\"):\n",
    "    x= item1.split(\":\")\n",
    "    layer =[]\n",
    "    layer.append(x[0].strip())\n",
    "    layer.append(int(x[1].strip()))\n",
    "    layers.append(layer)\n",
    "given_ang =[]\n",
    "given_ang.append([])\n",
    "given_ang.append([])\n",
    "# given_ang.append(norm_para)\n",
    "model = Net(img_size,layers,False,False,given_ang,False)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "# print(quantum_matrix)\n",
    "to_quantum_data = ToQuantumData(img_size)\n",
    "output_data = to_quantum_data(data)\n",
    "output = model.forward(output_data,False)\n",
    "print(\"classical inference:\",output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}