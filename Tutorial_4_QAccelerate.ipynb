{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Non-Optimized Circuit and Optimized Circuit\n",
    "\n",
    "The algorithm used in this toturial is from [QuantumFlow](https://www.nature.com/articles/s41467-020-20729-5) (Box-2 on Page 10). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch  \n",
    "    print('Module torch was installed')\n",
    "except ImportError:    \n",
    "    print(\"Installinng torch 1.8.1\")\n",
    "    !pip install -q torch==1.8.1\n",
    "    import qiskit  \n",
    "\n",
    "try:\n",
    "    import torchvision  \n",
    "    print('Module torchvision was installed')\n",
    "except ImportError:    \n",
    "    print(\"Installinng torchvision 0.4.0\")\n",
    "    !pip install -q torchvision==0.4.0\n",
    "    import qiskit  \n",
    "\n",
    "try:\n",
    "    import qiskit  \n",
    "    print('Module qiskit was installed')\n",
    "except ImportError:    \n",
    "    print(\"Installinng qiskit 0.14.0\")\n",
    "    !pip install -q qiskit==0.14.0\n",
    "    import qiskit  \n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import functools\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "from qiskit import Aer, execute\n",
    "import qiskit\n",
    "import math\n",
    "\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "interest_num = [3,6]\n",
    "ori_img_size = 28\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "# Weiwen: modify the target classes starting from 0. Say, [3,6] -> [0,1]\n",
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "# Weiwen: select sub-set from MNIST\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    return dataset\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum data\n",
    "######################################################\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        output_data = output_matrix[:, 0].view(1, img_size,img_size)\n",
    "        return output_data\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum matrix\n",
    "######################################################\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        return output_matrix       \n",
    "    \n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: fire_ibmq from Listing 6\n",
    "# Note: used for execute quantum circuit using \n",
    "#       simulation or ibm quantum processor\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2) number of shots;\n",
    "#             (3) simulation or quantum processor;\n",
    "#             (4) backend name if quantum processor.\n",
    "######################################################\n",
    "def fire_ibmq(circuit,shots,Simulation = False,backend_name='ibmq_essex'):     \n",
    "    count_set = []\n",
    "    if not Simulation:\n",
    "        provider = IBMQ.get_provider('ibm-q-academic')\n",
    "        backend = provider.get_backend(backend_name)\n",
    "    else:\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "    job_ibm_q = execute(circuit, backend, shots=shots)\n",
    "    job_monitor(job_ibm_q)\n",
    "    result_ibm_q = job_ibm_q.result()\n",
    "    counts = result_ibm_q.get_counts()\n",
    "    return counts\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: analyze from Listing 6\n",
    "# Note: used for analyze the count on states to  \n",
    "#       formulate the probability for each qubit\n",
    "# Parameters: (1) counts returned by fire_ibmq; \n",
    "######################################################\n",
    "def analyze(counts):\n",
    "    mycount = {}\n",
    "    for i in range(2):\n",
    "        mycount[i] = 0\n",
    "    for k,v in counts.items():\n",
    "        bits = len(k) \n",
    "        for i in range(bits):            \n",
    "            if k[bits-1-i] == \"1\":\n",
    "                if i in mycount.keys():\n",
    "                    mycount[i] += v\n",
    "                else:\n",
    "                    mycount[i] = v\n",
    "    return mycount,bits\n",
    "\n",
    "\n",
    "\n",
    "################ Weiwen on 06-02-2021 ################\n",
    "# Function: ccz from Listing 3\n",
    "# Note: using the basic Toffoli gates and CZ gate\n",
    "#       to implement ccz gate, which will flip the\n",
    "#       sign of state |111>\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2-3) control qubits;\n",
    "#             (4) target qubits;\n",
    "#             (5) auxiliary qubits.\n",
    "######################################################\n",
    "def ccz(circ, q1, q2, q3, aux1):\n",
    "    # Apply Z-gate to a state controlled by 3 qubits\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    circ.cz(aux1, q3)\n",
    "    # cleaning the aux bit\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    return circ\n",
    "\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: cccz from Listing 3\n",
    "# Note: using the basic Toffoli gates and CZ gate\n",
    "#       to implement cccz gate, which will flip the\n",
    "#       sign of state |1111>\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2-4) control qubits;\n",
    "#             (5) target qubits;\n",
    "#             (6-7) auxiliary qubits.\n",
    "######################################################\n",
    "def cccz(circ, q1, q2, q3, q4, aux1, aux2):\n",
    "    # Apply Z-gate to a state controlled by 4 qubits\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    circ.ccx(q3, aux1, aux2)\n",
    "    circ.cz(aux2, q4)\n",
    "    # cleaning the aux bits\n",
    "    circ.ccx(q3, aux1, aux2)\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    return circ\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: cccz from Listing 4\n",
    "# Note: using the basic Toffoli gate to implement ccccx\n",
    "#       gate. It is used to switch the quantum states\n",
    "#       of |11110> and |11111>.\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2-5) control qubits;\n",
    "#             (6) target qubits;\n",
    "#             (7-8) auxiliary qubits.\n",
    "######################################################\n",
    "def ccccx(circ, q1, q2, q3, q4, q5, aux1, aux2):\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    circ.ccx(q3, q4, aux2)\n",
    "    circ.ccx(aux2, aux1, q5)\n",
    "    # cleaning the aux bits\n",
    "    circ.ccx(q3, q4, aux2)\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    return circ\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: neg_weight_gate from Listing 3\n",
    "# Note: adding NOT(X) gate before the qubits associated\n",
    "#       with 0 state. For example, if we want to flip \n",
    "#       the sign of |1101>, we add X gate for q2 before\n",
    "#       the cccz gate, as follows.\n",
    "#       --q3-----|---\n",
    "#       --q2----X|X--\n",
    "#       --q1-----|---\n",
    "#       --q0-----z---\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2) all qubits, say q0-q3;\n",
    "#             (3) the auxiliary qubits used for cccz\n",
    "#             (4) states, say 1101\n",
    "######################################################\n",
    "def neg_weight_gate(circ,qubits,aux,state):\n",
    "    idx = 0\n",
    "    # The index of qubits are reversed in terms of states.\n",
    "    # As shown in the above example: we put X at q2 not the third position.\n",
    "    state = state[::-1]\n",
    "    for idx in range(len(state)):\n",
    "        if state[idx]=='0':\n",
    "            circ.x(qubits[idx])\n",
    "    cccz(circ,qubits[0],qubits[1],qubits[2],qubits[3],aux[0],aux[1])\n",
    "    for idx in range(len(state)):\n",
    "        if state[idx]=='0':\n",
    "            circ.x(qubits[idx])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Using torch to load MNIST data\n",
    "######################################################\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# T1: Downsample the image from 28*28 to 4*4\n",
    "# T2: Convert classical data to quantum data which \n",
    "#     can be encoded to the quantum states (amplitude)\n",
    "######################################################\n",
    "\n",
    "# Process data by hand, we can also integrate ToQuantumData into transform\n",
    "def data_pre_pro(img):\n",
    "    # Print original figure\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    # Print resized figure\n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    plt.show()\n",
    "    # Converting classical data to quantum data\n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_vector = ToQuantumData()\n",
    "    trans_to_matrix = ToQuantumMatrix()    \n",
    "    print(\"Classical Data: {}\".format(trans_to_tensor(im).flatten()))\n",
    "    print(\"Quantum Data: {}\".format(trans_to_vector(trans_to_tensor(im)).flatten()))\n",
    "    return trans_to_matrix(trans_to_tensor(im)),trans_to_vector(trans_to_tensor(im))\n",
    "\n",
    "# Use the first image from test loader as example\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we appiled the tained weights obtained from QF-FB, which will be introduced in the later tutorial. \n",
    "But, at this moment, feel free to change the weights to see the circuit depth comparison.\n",
    "\n",
    "For eaxmple, the following weights will lead the depth comparison to be 93:33.\n",
    "<pre><code>weight_1_1 = torch.tensor([1.,  -1.,  -1.,  1.,  -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., 1., 1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])</code></pre> "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Parameters of the trained model\n",
    "# The training procedure will be found in another repo\n",
    "# https://github.com/weiwenjiang/QuantumFlow\n",
    "######################################################\n",
    "\n",
    "# Model initialization\n",
    "weight_1_1 = torch.tensor([1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])\n",
    "\n",
    "weight_2_1 = torch.tensor([1.,  -1.])\n",
    "norm_flag_1 = True\n",
    "norm_para_1 = torch.tensor(0.3060)\n",
    "\n",
    "weight_2_2 = torch.tensor([-1.,  -1.])\n",
    "norm_flag_2 = False\n",
    "norm_para_2 = torch.tensor(0.6940)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Non-optimized Circuit\n",
    "\n",
    "The same with Tutorial 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum circuit implementation\n",
    "######################################################\n",
    "\n",
    "# From Listing 2: creat the qubits to hold data\n",
    "inp_1 = QuantumRegister(4,\"in1_qbit\")\n",
    "inp_2 = QuantumRegister(4,\"in2_qbit\")\n",
    "circ = QuantumCircuit(inp_1,inp_2)\n",
    "data_matrix = quantum_matrix\n",
    "circ.append(UnitaryGate(data_matrix, label=\"Input\"), inp_1[0:4])\n",
    "circ.append(UnitaryGate(data_matrix, label=\"Input\"), inp_2[0:4])\n",
    "\n",
    "# From Listing 3: create auxiliary qubits\n",
    "aux = QuantumRegister(2,\"aux_qbit\")\n",
    "circ.add_register(aux)\n",
    "\n",
    "# From Listing 4: create output qubits for the first layer (hidden neurons)\n",
    "hidden_neurons = QuantumRegister(2,\"hidden_qbits\")\n",
    "circ.add_register(hidden_neurons)\n",
    "\n",
    "\n",
    "# From Listing 3: to multiply inputs and weights on quantum circuit\n",
    "if weight_1_1.sum()<0:\n",
    "    weight_1_1 = weight_1_1*-1\n",
    "idx = 0\n",
    "for idx in range(weight_1_1.flatten().size()[0]):\n",
    "    if weight_1_1[idx]==-1:\n",
    "        state = \"{0:b}\".format(idx).zfill(4)\n",
    "        neg_weight_gate(circ,inp_1,aux,state)\n",
    "        circ.barrier()\n",
    "\n",
    "if weight_1_2.sum()<0:\n",
    "    weight_1_2 = weight_1_2*-1\n",
    "idx = 0\n",
    "for idx in range(weight_1_2.flatten().size()[0]):\n",
    "    if weight_1_2[idx]==-1:\n",
    "        state = \"{0:b}\".format(idx).zfill(4)\n",
    "        neg_weight_gate(circ,inp_2,aux,state)\n",
    "        circ.barrier()\n",
    "        \n",
    "# From Listing 4: applying the quadratic function on the weighted sum\n",
    "circ.h(inp_1)\n",
    "circ.x(inp_1)\n",
    "ccccx(circ,inp_1[0],inp_1[1],inp_1[2],inp_1[3],hidden_neurons[0],aux[0],aux[1])\n",
    "\n",
    "circ.h(inp_2)\n",
    "circ.x(inp_2)\n",
    "ccccx(circ,inp_2[0],inp_2[1],inp_2[2],inp_2[3],hidden_neurons[1],aux[0],aux[1])\n",
    "\n",
    "\n",
    "print(\"Hidden layer created!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum circuit implementation of the output layer\n",
    "# fundamentals, please see our Nature Communication\n",
    "# paper (P-LYR) https://arxiv.org/pdf/2006.14815.pdf\n",
    "######################################################\n",
    "\n",
    "inter_q_1 = QuantumRegister(1,\"inter_q_1_qbits\")\n",
    "norm_q_1 = QuantumRegister(1,\"norm_q_1_qbits\")\n",
    "out_q_1 = QuantumRegister(1,\"out_q_1_qbits\")\n",
    "circ.add_register(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "if weight_2_1.sum()<0:\n",
    "    weight_2_1 = weight_2_1*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        circ.x(hidden_neurons[idx])\n",
    "circ.h(inter_q_1)\n",
    "circ.cz(hidden_neurons[0],inter_q_1)\n",
    "circ.x(inter_q_1)\n",
    "circ.cz(hidden_neurons[1],inter_q_1)\n",
    "circ.x(inter_q_1)\n",
    "circ.h(inter_q_1)\n",
    "circ.x(inter_q_1)\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_1.sqrt().arcsin()*2)\n",
    "circ.ry(norm_init_rad,norm_q_1)\n",
    "if norm_flag_1:\n",
    "    circ.cx(inter_q_1,out_q_1)\n",
    "    circ.x(inter_q_1)\n",
    "    circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "else:\n",
    "    circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        circ.x(hidden_neurons[idx])\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inter_q_2 = QuantumRegister(1,\"inter_q_2_qbits\")\n",
    "norm_q_2 = QuantumRegister(1,\"norm_q_2_qbits\")\n",
    "out_q_2 = QuantumRegister(1,\"out_q_2_qbits\")\n",
    "circ.add_register(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "if weight_2_2.sum()<0:\n",
    "    weight_2_2 = weight_2_2*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        circ.x(hidden_neurons[idx])\n",
    "circ.h(inter_q_2)\n",
    "circ.cz(hidden_neurons[0],inter_q_2)\n",
    "circ.x(inter_q_2)\n",
    "circ.cz(hidden_neurons[1],inter_q_2)\n",
    "circ.x(inter_q_2)\n",
    "circ.h(inter_q_2)\n",
    "circ.x(inter_q_2)\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_2.sqrt().arcsin()*2)\n",
    "circ.ry(norm_init_rad,norm_q_2)\n",
    "if norm_flag_2:\n",
    "    circ.cx(inter_q_2,out_q_2)\n",
    "    circ.x(inter_q_2)\n",
    "    circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "else:\n",
    "    circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        circ.x(hidden_neurons[idx])\n",
    "\n",
    "circ.barrier()\n",
    "\n",
    "c_reg = ClassicalRegister(2,\"reg\")\n",
    "circ.add_register(c_reg)\n",
    "circ.measure(out_q_1,c_reg[0])\n",
    "circ.measure(out_q_2,c_reg[1])\n",
    "\n",
    "print(\"Output layer created!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimized Circuit\n",
    "\n",
    "In the following, the optimized circuit (opt_circ) is created"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 06-02-2021 ################\n",
    "# QuantumFlow Weight Generation for U-Layer\n",
    "######################################################\n",
    "\n",
    "def get_index_list(input,target):\n",
    "    index_list = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = input.index(target,beg_pos)\n",
    "            index_list.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    return index_list\n",
    "\n",
    "def change_sign(sign,bin):\n",
    "    affect_num = [bin]\n",
    "    one_positions = []\n",
    "    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = bin.index(\"1\",beg_pos)\n",
    "            one_positions.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:\n",
    "        # print(\"Not Found\")\n",
    "        pass\n",
    "    \n",
    "    for k,v in sign.items():\n",
    "        change = True\n",
    "        for pos in one_positions:\n",
    "            if k[pos]==\"0\":                \n",
    "                change = False\n",
    "                break\n",
    "        if change:\n",
    "            sign[k] = -1*v\n",
    "    \n",
    "\n",
    "def find_start(affect_count_table,target_num):\n",
    "    for k in list(affect_count_table.keys())[::-1]:\n",
    "        if target_num<=k:\n",
    "            return k\n",
    "\n",
    "\n",
    "def recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates):\n",
    "    \n",
    "    if start_point == target_num:\n",
    "        # print(\"recursive_change: STOP\")\n",
    "        return\n",
    "    \n",
    "    gap = int(math.fabs(start_point-target_num))    \n",
    "    step = find_start(affect_count_table,gap)\n",
    "    change_sign(sign,affect_count_table[step])\n",
    "    quantum_gates.append(affect_count_table[step])\n",
    "    \n",
    "    if direction==\"r\": \n",
    "        # print(\"recursive_change: From\",start_point,\"Right(-):\",step)\n",
    "        start_point = start_point - step\n",
    "        direction = \"l\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    else:        \n",
    "        # print(\"recursive_change: From\",start_point,\"Left(+):\",step)\n",
    "        start_point = start_point + step\n",
    "        direction = \"r\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    \n",
    "\n",
    "def guarntee_upper_bound_algorithm(sign,target_num,total_len,digits):        \n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    pre_num = 0\n",
    "    affect_count_table = {}\n",
    "    quantum_gates = []\n",
    "    for i in range(digits):\n",
    "        cur_num = pre_num + pow(2,i)\n",
    "        pre_num = cur_num\n",
    "        binstr_cur_num = format(cur_num,flag) \n",
    "        affect_count_table[int(pow(2,binstr_cur_num.count(\"0\")))] = binstr_cur_num   \n",
    "        \n",
    "    if target_num in affect_count_table.keys():\n",
    "        quantum_gates.append(affect_count_table[target_num])\n",
    "        change_sign(sign,affect_count_table[target_num])    \n",
    "    else:\n",
    "        direction = \"r\"\n",
    "        start_point = find_start(affect_count_table,target_num)\n",
    "        quantum_gates.append(affect_count_table[start_point])\n",
    "        change_sign(sign,affect_count_table[start_point])\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "    \n",
    "    return quantum_gates\n",
    "\n",
    "def qf_map_extract_from_weight(weights):    \n",
    "    # Find Z control gates according to weights\n",
    "    w = (weights.detach().cpu().numpy())\n",
    "    total_len = len(w)\n",
    "    target_num = np.count_nonzero(w == -1)\n",
    "    if target_num > total_len/2:\n",
    "        w = w*-1\n",
    "    target_num = np.count_nonzero(w == -1)    \n",
    "    digits = int(math.log(total_len,2))\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    max_num = int(math.pow(2,digits))\n",
    "    sign = {}\n",
    "    for i in range(max_num):        \n",
    "        sign[format(i,flag)] = +1\n",
    "    quantum_gates = guarntee_upper_bound_algorithm(sign,target_num,total_len,digits)\n",
    "    \n",
    "    # Build the mapping from weight to final negative num \n",
    "    fin_sign = list(sign.values())\n",
    "    fin_weig = [int(x) for x in list(w)]\n",
    "    sign_neg_index = []    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_sign.index(-1,beg_pos)            \n",
    "            # qiskit_position = int(format(find_pos,flag)[::-1],2)                            \n",
    "            sign_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    \n",
    "\n",
    "    weight_neg_index = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_weig.index(-1,beg_pos)\n",
    "            weight_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    map = {}\n",
    "    for i in range(len(sign_neg_index)):\n",
    "        map[sign_neg_index[i]] = weight_neg_index[i]\n",
    "\n",
    "    ret_index = list([-1 for i in range(len(fin_weig))])\n",
    "    \n",
    "    \n",
    "    for k,v in map.items():\n",
    "        ret_index[k]=v\n",
    "    \n",
    "    \n",
    "    for i in range(len(fin_weig)):\n",
    "        if ret_index[i]!=-1:\n",
    "            continue\n",
    "        for j in range(len(fin_weig)):\n",
    "            if j not in ret_index:\n",
    "                ret_index[i]=j\n",
    "                break\n",
    "    return quantum_gates,ret_index\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimized circuit\n",
    "\n",
    "# From Listing 2: creat the qubits to hold data\n",
    "inp_1 = QuantumRegister(4,\"in1_qbit\")\n",
    "inp_2 = QuantumRegister(4,\"in2_qbit\")\n",
    "opt_circ = QuantumCircuit(inp_1,inp_2)\n",
    "data_matrix = quantum_matrix\n",
    "\n",
    "n1_q_gates,n1_idx = qf_map_extract_from_weight(weight_1_1)\n",
    "n2_q_gates,n2_idx = qf_map_extract_from_weight(weight_1_2)\n",
    "\n",
    "opt_circ.append(UnitaryGate(data_matrix[n1_idx], label=\"Input\"), inp_1[0:4])\n",
    "opt_circ.append(UnitaryGate(data_matrix[n2_idx], label=\"Input\"), inp_2[0:4])\n",
    "\n",
    "# From Listing 3: create auxiliary qubits\n",
    "aux = QuantumRegister(2,\"aux_qbit\")\n",
    "opt_circ.add_register(aux)\n",
    "\n",
    "# From Listing 4: create output qubits for the first layer (hidden neurons)\n",
    "hidden_neurons = QuantumRegister(2,\"hidden_qbits\")\n",
    "opt_circ.add_register(hidden_neurons)\n",
    "\n",
    "\n",
    "qbits = inp_1\n",
    "for gate in n1_q_gates:\n",
    "    z_count = gate.count(\"1\")\n",
    "    # z_pos = get_index_list(gate,\"1\")\n",
    "    z_pos = get_index_list(gate[::-1],\"1\")\n",
    "    # print(z_pos)\n",
    "    if z_count==1:\n",
    "        opt_circ.z(qbits[z_pos[0]])\n",
    "    elif z_count==2:\n",
    "        opt_circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "    elif z_count==3:\n",
    "        ccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux[0])\n",
    "    elif z_count==4:\n",
    "        cccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux[0],aux[1])\n",
    "\n",
    "qbits = inp_2\n",
    "for gate in n2_q_gates:\n",
    "    z_count = gate.count(\"1\")\n",
    "    # z_pos = get_index_list(gate,\"1\")\n",
    "    z_pos = get_index_list(gate[::-1],\"1\")\n",
    "    # print(z_pos)\n",
    "    if z_count==1:\n",
    "        opt_circ.z(qbits[z_pos[0]])\n",
    "    elif z_count==2:\n",
    "        opt_circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "    elif z_count==3:\n",
    "        ccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux[0])\n",
    "    elif z_count==4:\n",
    "        cccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux[0],aux[1])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "# From Listing 4: applying the quadratic function on the weighted sum\n",
    "opt_circ.h(inp_1)\n",
    "opt_circ.x(inp_1)\n",
    "ccccx(opt_circ,inp_1[0],inp_1[1],inp_1[2],inp_1[3],hidden_neurons[0],aux[0],aux[1])\n",
    "\n",
    "opt_circ.h(inp_2)\n",
    "opt_circ.x(inp_2)\n",
    "ccccx(opt_circ,inp_2[0],inp_2[1],inp_2[2],inp_2[3],hidden_neurons[1],aux[0],aux[1])\n",
    "\n",
    "\n",
    "print(\"Hidden layer created!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum circuit implementation of the output layer\n",
    "# fundamentals, please see our Nature Communication\n",
    "# paper (P-LYR) https://arxiv.org/pdf/2006.14815.pdf\n",
    "######################################################\n",
    "\n",
    "inter_q_1 = QuantumRegister(1,\"inter_q_1_qbits\")\n",
    "norm_q_1 = QuantumRegister(1,\"norm_q_1_qbits\")\n",
    "out_q_1 = QuantumRegister(1,\"out_q_1_qbits\")\n",
    "opt_circ.add_register(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "if weight_2_1.sum()<0:\n",
    "    weight_2_1 = weight_2_1*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "opt_circ.h(inter_q_1)\n",
    "opt_circ.cz(hidden_neurons[0],inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "opt_circ.cz(hidden_neurons[1],inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "opt_circ.h(inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_1.sqrt().arcsin()*2)\n",
    "opt_circ.ry(norm_init_rad,norm_q_1)\n",
    "if norm_flag_1:\n",
    "    opt_circ.cx(inter_q_1,out_q_1)\n",
    "    opt_circ.x(inter_q_1)\n",
    "    opt_circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "else:\n",
    "    opt_circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inter_q_2 = QuantumRegister(1,\"inter_q_2_qbits\")\n",
    "norm_q_2 = QuantumRegister(1,\"norm_q_2_qbits\")\n",
    "out_q_2 = QuantumRegister(1,\"out_q_2_qbits\")\n",
    "opt_circ.add_register(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "if weight_2_2.sum()<0:\n",
    "    weight_2_2 = weight_2_2*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "opt_circ.h(inter_q_2)\n",
    "opt_circ.cz(hidden_neurons[0],inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "opt_circ.cz(hidden_neurons[1],inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "opt_circ.h(inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_2.sqrt().arcsin()*2)\n",
    "opt_circ.ry(norm_init_rad,norm_q_2)\n",
    "if norm_flag_2:\n",
    "    opt_circ.cx(inter_q_2,out_q_2)\n",
    "    opt_circ.x(inter_q_2)\n",
    "    opt_circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "else:\n",
    "    opt_circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "c_reg = ClassicalRegister(2,\"reg\")\n",
    "opt_circ.add_register(c_reg)\n",
    "opt_circ.measure(out_q_1,c_reg[0])\n",
    "opt_circ.measure(out_q_2,c_reg[1])\n",
    "\n",
    "print(\"Output layer created!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Non-Optimized Circuit v.s. Optimized Circuit\n",
    "\n",
    "Let's test and compare!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum simulation\n",
    "######################################################\n",
    "\n",
    "# Non-Optimized one\n",
    "qc_shots=8192\n",
    "counts = fire_ibmq(circ,qc_shots,True)\n",
    "(mycount,bits) = analyze(counts)\n",
    "class_prob=[]\n",
    "for b in range(bits):\n",
    "    class_prob.append(float(mycount[b])/qc_shots)\n",
    "\n",
    "print(\"=\"*10,\"Non-Optimized Circuit\",\"=\"*10)\n",
    "print(\"Non-Optimized Circuit Depth:\",circ.depth())\n",
    "print(\"Result of non-optimized QC:\",class_prob)\n",
    "print(\"Prediction class: {}\".format(class_prob.index(max(class_prob))))\n",
    "print(\"Target class: {}\".format(target[0]))\n",
    "if class_prob.index(max(class_prob))==target[0]:\n",
    "    print(\"Correct prediction\")\n",
    "else:\n",
    "    print(\"Incorrect prediction\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Optimized one\n",
    "qc_shots=8192\n",
    "opt_counts = fire_ibmq(opt_circ,qc_shots,True)\n",
    "(opt_mycount,bits) = analyze(opt_counts)\n",
    "opt_class_prob=[]\n",
    "for b in range(bits):\n",
    "    opt_class_prob.append(float(opt_mycount[b])/qc_shots)\n",
    "\n",
    "\n",
    "print(\"=\"*10,\"Optimized Circuit\",\"=\"*10)\n",
    "print(\"Optimized Circuit Depth:\",opt_circ.depth())\n",
    "print(\"Result of optimized QC:\",opt_class_prob)\n",
    "print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\n",
    "print(\"Target class: {}\".format(target[0]))\n",
    "if opt_class_prob.index(max(opt_class_prob))==target[0]:\n",
    "    print(\"Correct prediction\")\n",
    "else:\n",
    "    print(\"Incorrect prediction\")\n",
    "print(\"=\"*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}