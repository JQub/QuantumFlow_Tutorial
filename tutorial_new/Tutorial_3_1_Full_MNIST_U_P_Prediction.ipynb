{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "is_colab = False\n",
    "import sys\n",
    "if is_colab:\n",
    "    try:\n",
    "        import torch  \n",
    "        print('Module torch was installed')\n",
    "    except ImportError:    \n",
    "        print(\"Installinng torch 1.8.1\")\n",
    "        !pip install -q torch==1.8.1\n",
    "    try:\n",
    "        import torchvision  \n",
    "        print('Module torchvision was installed')\n",
    "    except ImportError:    \n",
    "        print(\"Installinng torchvision 0.4.0\")\n",
    "        !pip install -q torchvision==0.4.0\n",
    "    \n",
    "    try:\n",
    "        import qiskit  \n",
    "        print('Module qiskit was installed')\n",
    "    except ImportError:    \n",
    "        print(\"Installinng qiskit 0.14.0\")\n",
    "        !pip install -q qiskit==0.14.0\n",
    "\n",
    "    !pip install JQuantumFlow==0.0.5\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "import qiskit\n",
    "import math\n",
    "\n",
    "from JQuantumFlow.training.lib_dataloader import load_data,to_quantum_matrix,ToQuantumData\n",
    "from JQuantumFlow.circuit.lib_gate import ExtendGate\n",
    "from JQuantumFlow.circuit.lib_qiskit_commons import fire_ibmq,analyze"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "################ Zhirui on 12-30-2020 ################\n",
    "# Parameters of settings\n",
    "######################################################\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    " # how many samples per batch \n",
    "batch_size = 1 \n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "################ Zhirui on 12-30-2020 ################\n",
    "# path\n",
    "######################################################\n",
    "if is_colab:\n",
    "    data_path = '/content/data' #mnist  path\n",
    "else: \n",
    "    data_path = '/home/hzr/Software/quantum/qc_mnist/pytorch/data'\n",
    "\n",
    "################ Zhirui on 12-30-2020 ################\n",
    "#load data and do data preparation\n",
    "######################################################\n",
    "\n",
    "train_loader, test_loader = load_data(interest_num,data_path,False,img_size,batch_size,inference_batch_size,False)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix = to_quantum_matrix(data)\n",
    "    to_quantum_data = ToQuantumData(img_size)\n",
    "    quantum_data = to_quantum_data(data)\n",
    "    break\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch Id: 0, Target: tensor([1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we appiled the tained weights obtained from QF-FB, which will be introduced in the later tutorial. \n",
    "But, at this moment, feel free to change the weights to see the circuit depth comparison.\n",
    "\n",
    "For eaxmple, the following weights will lead the depth comparison to be 93:33.\n",
    "<pre><code>weight_1_1 = torch.tensor([1.,  -1.,  -1.,  1.,  -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., 1., 1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])</code></pre> "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Parameters of the trained model\n",
    "# The training procedure will be found in another repo\n",
    "# https://github.com/weiwenjiang/QuantumFlow\n",
    "######################################################\n",
    "\n",
    "# Model initialization\n",
    "weight_1_1 = torch.tensor([1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])\n",
    "\n",
    "weight_2_1 = torch.tensor([1.,  -1.])\n",
    "norm_flag_1 = True\n",
    "norm_para_1 = torch.tensor(0.3060)\n",
    "\n",
    "weight_2_2 = torch.tensor([-1.,  -1.])\n",
    "norm_flag_2 = False\n",
    "norm_para_2 = torch.tensor(0.6940)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimized Circuit\n",
    "\n",
    "In the following, the optimized circuit (opt_circ) is created"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "################ Weiwen on 06-02-2021 ################\n",
    "# QuantumFlow Weight Generation for U-Layer\n",
    "######################################################\n",
    "\n",
    "def get_index_list(input,target):\n",
    "    index_list = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = input.index(target,beg_pos)\n",
    "            index_list.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "    return index_list\n",
    "#\n",
    "def change_sign(sign,bin):\n",
    "    affect_num = [bin]\n",
    "    one_positions = []\n",
    "    print(\"bin :\",bin)\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = bin.index(\"1\",beg_pos)\n",
    "            one_positions.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:\n",
    "        # print(\"Not Found\")\n",
    "        pass\n",
    "    for k,v in sign.items():\n",
    "        change = True\n",
    "        for pos in one_positions:\n",
    "            if k[pos]==\"0\":                \n",
    "                change = False\n",
    "                break\n",
    "        if change:\n",
    "            sign[k] = -1*v\n",
    "    \n",
    "\n",
    "def find_start(affect_count_table,target_num):\n",
    "    for k in list(affect_count_table.keys())[::-1]:\n",
    "        if target_num<=k:\n",
    "            return k\n",
    "\n",
    "\n",
    "def recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates):\n",
    "    \n",
    "    if start_point == target_num:\n",
    "        # print(\"recursive_change: STOP\")\n",
    "        return\n",
    "    \n",
    "    gap = int(math.fabs(start_point-target_num))    \n",
    "    step = find_start(affect_count_table,gap)\n",
    "    change_sign(sign,affect_count_table[step])\n",
    "    quantum_gates.append(affect_count_table[step])\n",
    "    \n",
    "    if direction==\"r\": \n",
    "        # print(\"recursive_change: From\",start_point,\"Right(-):\",step)\n",
    "        start_point = start_point - step\n",
    "        direction = \"l\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    else:        \n",
    "        # print(\"recursive_change: From\",start_point,\"Left(+):\",step)\n",
    "        start_point = start_point + step\n",
    "        direction = \"r\"\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "        \n",
    "    \n",
    "\n",
    "def guarntee_upper_bound_algorithm(sign,target_num,total_len,digits):        \n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    pre_num = 0\n",
    "    affect_count_table = {}\n",
    "    quantum_gates = []\n",
    "    for i in range(digits):\n",
    "        cur_num = pre_num + pow(2,i)\n",
    "        pre_num = cur_num\n",
    "        binstr_cur_num = format(cur_num,flag) \n",
    "        affect_count_table[int(pow(2,binstr_cur_num.count(\"0\")))] = binstr_cur_num   \n",
    "    \n",
    "    if target_num in affect_count_table.keys():\n",
    "        quantum_gates.append(affect_count_table[target_num])\n",
    "        change_sign(sign,affect_count_table[target_num])  \n",
    "  \n",
    "    else:\n",
    "        direction = \"r\"\n",
    "        start_point = find_start(affect_count_table,target_num)\n",
    "        quantum_gates.append(affect_count_table[start_point])\n",
    "        change_sign(sign,affect_count_table[start_point])\n",
    "        recursive_change(direction,start_point,target_num,sign,affect_count_table,quantum_gates)\n",
    "    \n",
    "    return quantum_gates\n",
    "\n",
    "def qf_map_extract_from_weight(weights):    \n",
    "    # Find Z control gates according to weights\n",
    "    w = (weights.detach().cpu().numpy())\n",
    "    total_len = len(w)\n",
    "    target_num = np.count_nonzero(w == -1)\n",
    "    if target_num > total_len/2:\n",
    "        w = w*-1\n",
    "    target_num = np.count_nonzero(w == -1)    \n",
    "    digits = int(math.log(total_len,2))\n",
    "    flag = \"0\"+str(digits)+\"b\"\n",
    "    max_num = int(math.pow(2,digits))\n",
    "    sign = {}\n",
    "    for i in range(max_num):        \n",
    "        sign[format(i,flag)] = +1\n",
    "\n",
    "    quantum_gates = guarntee_upper_bound_algorithm(sign,target_num,total_len,digits)\n",
    "    \n",
    "    # Build the mapping from weight to final negative num \n",
    "    fin_sign = list(sign.values())\n",
    "    fin_weig = [int(x) for x in list(w)]\n",
    "    sign_neg_index = []    \n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_sign.index(-1,beg_pos)            \n",
    "            # qiskit_position = int(format(find_pos,flag)[::-1],2)                            \n",
    "            sign_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass  \n",
    "    \n",
    "\n",
    "    weight_neg_index = []\n",
    "    try:\n",
    "        beg_pos = 0\n",
    "        while True:\n",
    "            find_pos = fin_weig.index(-1,beg_pos)\n",
    "            weight_neg_index.append(find_pos)\n",
    "            beg_pos = find_pos+1\n",
    "    except Exception as exception:        \n",
    "        pass    \n",
    "\n",
    "    map = {}\n",
    "    for i in range(len(sign_neg_index)):\n",
    "        map[sign_neg_index[i]] = weight_neg_index[i]\n",
    "\n",
    "    ret_index = list([-1 for i in range(len(fin_weig))])\n",
    "    \n",
    "    \n",
    "    for k,v in map.items():\n",
    "        ret_index[k]=v\n",
    "    \n",
    "    \n",
    "    for i in range(len(fin_weig)):\n",
    "        if ret_index[i]!=-1:\n",
    "            continue\n",
    "        for j in range(len(fin_weig)):\n",
    "            if j not in ret_index:\n",
    "                ret_index[i]=j\n",
    "                break\n",
    "    return quantum_gates,ret_index\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Optimized circuit\n",
    "\n",
    "# From Listing 2: creat the qubits to hold data\n",
    "inp_1 = QuantumRegister(4,\"in1_qbit\")\n",
    "inp_2 = QuantumRegister(4,\"in2_qbit\")\n",
    "opt_circ = QuantumCircuit(inp_1,inp_2)\n",
    "data_matrix = quantum_matrix\n",
    "\n",
    "n1_q_gates,n1_idx = qf_map_extract_from_weight(weight_1_1)\n",
    "n2_q_gates,n2_idx = qf_map_extract_from_weight(weight_1_2)\n",
    " \n",
    "print('n1_idx:',n1_idx)\n",
    "opt_circ.append(UnitaryGate(data_matrix[n1_idx], label=\"Input\"), inp_1[0:4])\n",
    "opt_circ.append(UnitaryGate(data_matrix[n2_idx], label=\"Input\"), inp_2[0:4])\n",
    "\n",
    "# From Listing 3: create auxiliary qubits\n",
    "aux = QuantumRegister(2,\"aux_qbit\")\n",
    "opt_circ.add_register(aux)\n",
    "\n",
    "# From Listing 4: create output qubits for the first layer (hidden neurons)\n",
    "hidden_neurons = QuantumRegister(2,\"hidden_qbits\")\n",
    "opt_circ.add_register(hidden_neurons)\n",
    "\n",
    "\n",
    "qbits = inp_1\n",
    "for gate in n1_q_gates:\n",
    "    z_count = gate.count(\"1\")\n",
    "    # z_pos = get_index_list(gate,\"1\")\n",
    "    z_pos = get_index_list(gate[::-1],\"1\")\n",
    "    # print(z_pos)\n",
    "    if z_count==1:\n",
    "        opt_circ.z(qbits[z_pos[0]])\n",
    "    elif z_count==2:\n",
    "        opt_circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "    elif z_count==3:\n",
    "        ExtendGate.ccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux[0])\n",
    "    elif z_count==4:\n",
    "        ExtendGate.cccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux[0],aux[1])\n",
    "\n",
    "qbits = inp_2\n",
    "for gate in n2_q_gates:\n",
    "    z_count = gate.count(\"1\")\n",
    "    # z_pos = get_index_list(gate,\"1\")\n",
    "    z_pos = get_index_list(gate[::-1],\"1\")\n",
    "    # print(z_pos)\n",
    "    if z_count==1:\n",
    "        opt_circ.z(qbits[z_pos[0]])\n",
    "    elif z_count==2:\n",
    "        opt_circ.cz(qbits[z_pos[0]],qbits[z_pos[1]])\n",
    "    elif z_count==3:\n",
    "        ExtendGate.ccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],aux[0])\n",
    "    elif z_count==4:\n",
    "        ExtendGate.cccz(opt_circ,qbits[z_pos[0]],qbits[z_pos[1]],qbits[z_pos[2]],qbits[z_pos[3]],aux[0],aux[1])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "# From Listing 4: applying the quadratic function on the weighted sum\n",
    "opt_circ.h(inp_1)\n",
    "opt_circ.x(inp_1)\n",
    "ExtendGate.ccccx(opt_circ,inp_1[0],inp_1[1],inp_1[2],inp_1[3],hidden_neurons[0],aux[0],aux[1])\n",
    "\n",
    "opt_circ.h(inp_2)\n",
    "opt_circ.x(inp_2)\n",
    "ExtendGate.ccccx(opt_circ,inp_2[0],inp_2[1],inp_2[2],inp_2[3],hidden_neurons[1],aux[0],aux[1])\n",
    "\n",
    "\n",
    "print(\"Hidden layer created!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bin : 0011\n",
      "bin : 1111\n",
      "bin : 0111\n",
      "n1_idx: [0, 1, 2, 7, 3, 4, 5, 9, 6, 8, 10, 11, 12, 13, 14, 15]\n",
      "Hidden layer created!\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum circuit implementation of the output layer\n",
    "# fundamentals, please see our Nature Communication\n",
    "# paper (P-LYR) https://arxiv.org/pdf/2006.14815.pdf\n",
    "######################################################\n",
    "\n",
    "inter_q_1 = QuantumRegister(1,\"inter_q_1_qbits\")\n",
    "norm_q_1 = QuantumRegister(1,\"norm_q_1_qbits\")\n",
    "out_q_1 = QuantumRegister(1,\"out_q_1_qbits\")\n",
    "opt_circ.add_register(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "if weight_2_1.sum()<0:\n",
    "    weight_2_1 = weight_2_1*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "opt_circ.h(inter_q_1)\n",
    "opt_circ.cz(hidden_neurons[0],inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "opt_circ.cz(hidden_neurons[1],inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "opt_circ.h(inter_q_1)\n",
    "opt_circ.x(inter_q_1)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_1.sqrt().arcsin()*2)\n",
    "opt_circ.ry(norm_init_rad,norm_q_1)\n",
    "if norm_flag_1:\n",
    "    opt_circ.cx(inter_q_1,out_q_1)\n",
    "    opt_circ.x(inter_q_1)\n",
    "    opt_circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "else:\n",
    "    opt_circ.ccx(inter_q_1,norm_q_1,out_q_1)\n",
    "\n",
    "for idx in range(weight_2_1.flatten().size()[0]):\n",
    "    if weight_2_1[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inter_q_2 = QuantumRegister(1,\"inter_q_2_qbits\")\n",
    "norm_q_2 = QuantumRegister(1,\"norm_q_2_qbits\")\n",
    "out_q_2 = QuantumRegister(1,\"out_q_2_qbits\")\n",
    "opt_circ.add_register(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "if weight_2_2.sum()<0:\n",
    "    weight_2_2 = weight_2_2*-1\n",
    "idx = 0\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "opt_circ.h(inter_q_2)\n",
    "opt_circ.cz(hidden_neurons[0],inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "opt_circ.cz(hidden_neurons[1],inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "opt_circ.h(inter_q_2)\n",
    "opt_circ.x(inter_q_2)\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "norm_init_rad = float(norm_para_2.sqrt().arcsin()*2)\n",
    "opt_circ.ry(norm_init_rad,norm_q_2)\n",
    "if norm_flag_2:\n",
    "    opt_circ.cx(inter_q_2,out_q_2)\n",
    "    opt_circ.x(inter_q_2)\n",
    "    opt_circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "else:\n",
    "    opt_circ.ccx(inter_q_2,norm_q_2,out_q_2)\n",
    "\n",
    "for idx in range(weight_2_2.flatten().size()[0]):\n",
    "    if weight_2_2[idx]==-1:\n",
    "        opt_circ.x(hidden_neurons[idx])\n",
    "\n",
    "opt_circ.barrier()\n",
    "\n",
    "c_reg = ClassicalRegister(2,\"reg\")\n",
    "opt_circ.add_register(c_reg)\n",
    "opt_circ.measure(out_q_1,c_reg[0])\n",
    "opt_circ.measure(out_q_2,c_reg[1])\n",
    "\n",
    "print(\"Output layer created!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output layer created!\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimized Circuit\n",
    "\n",
    "Let's test!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum simulation\n",
    "######################################################\n",
    "\n",
    "qc_shots=8192\n",
    "opt_counts = fire_ibmq(opt_circ,qc_shots,True)\n",
    "(opt_mycount,bits) = analyze(opt_counts)\n",
    "opt_class_prob=[]\n",
    "for b in range(bits):\n",
    "    opt_class_prob.append(float(opt_mycount[b])/qc_shots)\n",
    "\n",
    "\n",
    "print(\"=\"*10,\"Optimized Circuit\",\"=\"*10)\n",
    "print(\"Result of optimized QC:\",opt_class_prob)\n",
    "print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\n",
    "print(\"Target class: {}\".format(target[0]))\n",
    "if opt_class_prob.index(max(opt_class_prob))==target[0]:\n",
    "    print(\"Correct prediction\")\n",
    "else:\n",
    "    print(\"Incorrect prediction\")\n",
    "print(\"=\"*30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========== Optimized Circuit ==========\n",
      "Result of optimized QC: [0.4420166015625, 0.55322265625]\n",
      "Prediction class: 1\n",
      "Target class: 1\n",
      "Correct prediction\n",
      "==============================\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('qf': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "interpreter": {
   "hash": "f24048f0d5bdb0ff49c5e7c8a9899a65bc3ab13b0f32660a2227453ca6b95fd8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}