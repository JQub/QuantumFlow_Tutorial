{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to build the circuit of V-layer + U-layer "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare environment and  define parameters "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "is_colab = False\n",
    "import sys\n",
    "if is_colab:\n",
    "    !pip install -q torch==1.9.0\n",
    "    !pip install -q torchvision==0.10.0\n",
    "    !pip install -q qiskit==0.20.0\n",
    "    !pip install qfnn\n",
    "    !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w9VRv0iVfsH20Kb_MkF3yFhFeiYDVy5n' -O model.tar.gz\n",
    "    !tar zxvf /content/model.tar.gz\n",
    "\n",
    "\n",
    "import torch\n",
    "from qiskit import  QuantumCircuit, ClassicalRegister\n",
    "import numpy as np\n",
    "import functools\n",
    "from qfnn.qf_fb.q_output import fire_ibmq,analyze,add_measure\n",
    "from qfnn.qf_circ.f_lyr_circ import F_LYR_Circ\n",
    "from qfnn.qf_circ.v_lyr_circ import V_LYR_Circ\n",
    "from qfnn.qf_net.utils import binarize\n",
    "from qfnn.qf_fb.q_input import UMatrixCircuit\n",
    "from qfnn.qf_fb.c_input import load_data,to_quantum_matrix\n",
    "\n",
    "from qfnn.qf_fb.c_qf_mixer import Net\n",
    "from qfnn.qf_fb.c_input import ToQuantumData\n",
    "print = functools.partial(print, flush=True)\n",
    "################ Zhirui on 12-30-2020 ################\n",
    "# path\n",
    "# remember to change the path on your computer\n",
    "######################################################\n",
    "if is_colab:\n",
    "    data_path = '/content/data' #mnist  path\n",
    "    resume_path = '/content/model/v16_u2/model_best.tar' #model path\n",
    "else:\n",
    "    data_path = '/home/hzr/Software/quantum/qc_mnist/pytorch/data' #mnist  path\n",
    "    resume_path = '/home/hzr/Software/quantum/QuantumFlow_Tutorial/model/v16_u2/model_best.tar' #model path"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "################ Zhirui on 12-30-2020 ################\n",
    "# Parameters of settings\n",
    "######################################################\n",
    "interest_num = [3,6]\n",
    "img_size = 4\n",
    "batch_size = 1# how many samples per batch to load\n",
    "inference_batch_size = 1\n",
    "isppd = False #is prepared data\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_loader, test_loader = load_data(interest_num,data_path,isppd,img_size,batch_size,inference_batch_size,False)\n",
    "\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix = to_quantum_matrix(data)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wjiang8\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Id: 0, Target: tensor([1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### load model parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "################ hzr on 12-30-2020 ################\n",
    "# Get the parameters of the trained model\n",
    "######################################################\n",
    "\n",
    "# Model initialization\n",
    "checkpoint = torch.load(resume_path, map_location='cpu')\n",
    "print(checkpoint['state_dict']['fc0.theta'])\n",
    "print(checkpoint['state_dict']['fc1.weight'])\n",
    "theta = checkpoint['state_dict']['fc0.theta']\n",
    "weight = checkpoint['state_dict']['fc1.weight']\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hzr/Software/quantum/QuantumFlow_Tutorial/model/v16_u2/model_best.tar'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_29852/3962706902.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# Model initialization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mcheckpoint\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresume_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'cpu'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'state_dict'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'fc0.theta'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'state_dict'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'fc1.weight'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    592\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'encoding'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 594\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    595\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    596\u001B[0m             \u001B[1;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    231\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;34m'w'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/hzr/Software/quantum/QuantumFlow_Tutorial/model/v16_u2/model_best.tar'"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### data encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################ hzr on 12-30-2020 ################\n",
    "# Generate the circuit of u-Matrix\n",
    "######################################################\n",
    "\n",
    "#init circuit\n",
    "circuit = QuantumCircuit()\n",
    "#define your input and repeat number\n",
    "u_mat = UMatrixCircuit(4,2)\n",
    "#add input qubit to your circuit if needed\n",
    "inputs = u_mat.add_input_qubits(circuit)\n",
    "#add u-matrix to your circuit\n",
    "u_mat.forward(circuit,inputs,quantum_matrix)\n",
    "circuit.draw('text',fold=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### build the network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################ hzr on 12-30-2020 ################\n",
    "# Generate the circuit of v-layer\n",
    "######################################################\n",
    "\n",
    "#define your input and repeat number\n",
    "vqc = V_LYR_Circ(4,2)\n",
    "#add v-layer to your circuit\n",
    "vqc.forward(circuit,inputs,'v10',np.array(theta,dtype=np.double))\n",
    "\n",
    "circuit.draw('text',fold=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################ hzr on 12-30-2020 ################\n",
    "# Generate the circuit of f-layer\n",
    "######################################################\n",
    "\n",
    "#define your input and repeat number\n",
    "f_layer = F_LYR_Circ(4,2)\n",
    "\n",
    "#add auxiliary qubit to your circuit if needed\n",
    "aux =f_layer.add_aux(circuit)\n",
    "\n",
    "#add output qubit to your circuit if needed\n",
    "f_layer_out_qubits = f_layer.add_out_qubits(circuit)\n",
    "\n",
    "#add f-layer to your circuit\n",
    "f_layer.forward(circuit,binarize(weight),inputs,f_layer_out_qubits,None,aux)\n",
    "\n",
    "add_measure(circuit,f_layer_out_qubits,'reg')\n",
    "\n",
    "circuit.barrier()\n",
    "#add measurement to your circuit if needed\n",
    "\n",
    "\n",
    "circuit.draw('text',fold=300)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### simulation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum simulation\n",
    "######################################################\n",
    "\n",
    "\n",
    "qc_shots=8192\n",
    "opt_counts = fire_ibmq(circuit,qc_shots,True)\n",
    "(opt_mycount,bits) = analyze(opt_counts)\n",
    "opt_class_prob=[]\n",
    "for b in range(bits):\n",
    "    opt_class_prob.append(float(opt_mycount[b])/qc_shots)\n",
    "\n",
    "\n",
    "print(\"Simulation Result :\",opt_class_prob)\n",
    "print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\n",
    "print(\"Target class: {}\".format(target[0]))\n",
    "if opt_class_prob.index(max(opt_class_prob))==target[0]:\n",
    "    print(\"Correct prediction\")\n",
    "else:\n",
    "    print(\"Incorrect prediction\")\n",
    "print(\"=\"*30)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### classical inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "neural_in_layers = 'v:16,u:2'\n",
    "layers = []\n",
    "for item1 in neural_in_layers.split(\",\"):\n",
    "    x= item1.split(\":\")\n",
    "    layer =[]\n",
    "    layer.append(x[0].strip())\n",
    "    layer.append(int(x[1].strip()))\n",
    "    layers.append(layer)\n",
    "\n",
    "model = Net(img_size,layers,False,False)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "to_quantum_data = ToQuantumData(img_size)\n",
    "output_data = to_quantum_data(data)\n",
    "output = model.forward(output_data,False)\n",
    "print(\"classical inference result:\",output)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('qf': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "interpreter": {
   "hash": "f24048f0d5bdb0ff49c5e7c8a9899a65bc3ab13b0f32660a2227453ca6b95fd8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}