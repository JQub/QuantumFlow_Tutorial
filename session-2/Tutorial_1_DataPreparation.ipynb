{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# !pip install -q torch==1.8.1\n",
    "# !pip install -q torchvision==0.4.0\n",
    "# !pip install -q qiskit==0.20.0\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import qiskit  \n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import functools\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "interest_num = [3,6]\n",
    "ori_img_size = 28\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "# Weiwen: modify the target classes starting from 0. Say, [3,6] -> [0,1]\n",
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "# Weiwen: select sub-set from MNIST\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    return dataset\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum data\n",
    "######################################################\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        output_data = output_matrix[:, 0].view(1, img_size,img_size)\n",
    "        return output_data\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum matrix\n",
    "######################################################\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        return output_matrix                      "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Module torch was installed\n",
      "Module torchvision was installed\n",
      "Module qiskit was installed\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Using torch to load MNIST data\n",
    "######################################################\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# T1: Downsample the image from 28*28 to 4*4\n",
    "# T2: Convert classical data to quantum data which \n",
    "#     can be encoded to the quantum states (amplitude)\n",
    "######################################################\n",
    "\n",
    "# Process data by hand, we can also integrate ToQuantumData into transform\n",
    "def data_pre_pro(img):\n",
    "    # Print original figure\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    # Print resized figure\n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    plt.show()\n",
    "    # Converting classical data to quantum data\n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_vector = ToQuantumData()\n",
    "    trans_to_matrix = ToQuantumMatrix()    \n",
    "    print(\"Classical Data: {}\".format(trans_to_tensor(im).flatten()))\n",
    "    print(\"Quantum Data: {}\".format(trans_to_vector(trans_to_tensor(im)).flatten()))\n",
    "    return trans_to_matrix(trans_to_tensor(im)),trans_to_vector(trans_to_tensor(im))\n",
    "\n",
    "# Use the first image from test loader as example\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch Id: 0, Target: tensor([1])\n",
      "Classical Data: tensor([0.0000, 0.0941, 0.1922, 0.0000, 0.0078, 0.3373, 0.2706, 0.0667, 0.0196,\n",
      "        0.5098, 0.4941, 0.1843, 0.0078, 0.1176, 0.1137, 0.0118])\n",
      "Quantum Data: tensor([0.0000, 0.1051, 0.2145, 0.0000, 0.0088, 0.3764, 0.3020, 0.0744, 0.0219,\n",
      "        0.5690, 0.5515, 0.2057, 0.0088, 0.1313, 0.1269, 0.0131],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Do quantum state preparation and compare it with\n",
    "# the original data\n",
    "######################################################\n",
    "\n",
    "# Quantum-State Preparation in IBM Qiskit\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "from qiskit import Aer, execute\n",
    "import qiskit\n",
    "# Input: a 4*4 matrix (data) holding 16 input data\n",
    "inp = QuantumRegister(4,\"in_qbit\")\n",
    "circ = QuantumCircuit(inp)\n",
    "data_matrix = quantum_matrix\n",
    "circ.append(UnitaryGate(data_matrix, label=\"Input\"), inp[0:4])\n",
    "print(circ)\n",
    "# Using StatevectorSimulator from the Aer provider\n",
    "simulator = Aer.get_backend('statevector_simulator')\n",
    "result = execute(circ, simulator).result()\n",
    "statevector = result.get_statevector(circ)\n",
    "\n",
    "print(\"Data to be encoded: \\n {}\\n\".format(qantum_data))\n",
    "print(\"Data read from the circuit: \\n {}\".format(statevector))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              ┌──────────┐\n",
      "in_qbit_0: |0>┤0         ├\n",
      "              │          │\n",
      "in_qbit_1: |0>┤1         ├\n",
      "              │  unitary │\n",
      "in_qbit_2: |0>┤2         ├\n",
      "              │          │\n",
      "in_qbit_3: |0>┤3         ├\n",
      "              └──────────┘\n",
      "Data to be encoded: \n",
      " tensor([[[0.0000, 0.1051, 0.2145, 0.0000],\n",
      "         [0.0088, 0.3764, 0.3020, 0.0744],\n",
      "         [0.0219, 0.5690, 0.5515, 0.2057],\n",
      "         [0.0088, 0.1313, 0.1269, 0.0131]]], dtype=torch.float64)\n",
      "\n",
      "Data read from the circuit: \n",
      " [0.        +0.j 0.1050542 +0.j 0.21448566+0.j 0.        +0.j\n",
      " 0.00875452+0.j 0.37644423+0.j 0.30203084+0.j 0.0744134 +0.j\n",
      " 0.02188629+0.j 0.56904362+0.j 0.55153455+0.j 0.20573115+0.j\n",
      " 0.00875452+0.j 0.13131775+0.j 0.12694049+0.j 0.01313178+0.j]\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8213722",
   "language": "python",
   "display_name": "PyCharm (qiskit_practice)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}