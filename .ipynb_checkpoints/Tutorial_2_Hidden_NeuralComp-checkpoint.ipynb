{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import functools\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "from qiskit import Aer, execute\n",
    "import qiskit\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "interest_num = [3,6]\n",
    "ori_img_size = 28\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "# Weiwen: modify the target classes starting from 0. Say, [3,6] -> [0,1]\n",
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "# Weiwen: select sub-set from MNIST\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    return dataset\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum data\n",
    "######################################################\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        output_data = output_matrix[:, 0].view(1, img_size,img_size)\n",
    "        return output_data\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum matrix\n",
    "######################################################\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        return output_matrix       \n",
    "    \n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: fire_ibmq from Listing 6\n",
    "# Note: used for execute quantum circuit using \n",
    "#       simulation or ibm quantum processor\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2) number of shots;\n",
    "#             (3) simulation or quantum processor;\n",
    "#             (4) backend name if quantum processor.\n",
    "######################################################\n",
    "def fire_ibmq(circuit,shots,Simulation = False,backend_name='ibmq_essex'):     \n",
    "    count_set = []\n",
    "    if not Simulation:\n",
    "        provider = IBMQ.get_provider('ibm-q-academic')\n",
    "        backend = provider.get_backend(backend_name)\n",
    "    else:\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "    job_ibm_q = execute(circuit, backend, shots=shots)\n",
    "    job_monitor(job_ibm_q)\n",
    "    result_ibm_q = job_ibm_q.result()\n",
    "    counts = result_ibm_q.get_counts()\n",
    "    return counts\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: analyze from Listing 6\n",
    "# Note: used for analyze the count on states to  \n",
    "#       formulate the probability for each qubit\n",
    "# Parameters: (1) counts returned by fire_ibmq; \n",
    "######################################################\n",
    "def analyze(counts):\n",
    "    mycount = {}\n",
    "    for i in range(2):\n",
    "        mycount[i] = 0\n",
    "    for k,v in counts.items():\n",
    "        bits = len(k) \n",
    "        for i in range(bits):            \n",
    "            if k[bits-1-i] == \"1\":\n",
    "                if i in mycount.keys():\n",
    "                    mycount[i] += v\n",
    "                else:\n",
    "                    mycount[i] = v\n",
    "    return mycount,bits\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: cccz from Listing 3\n",
    "# Note: using the basic Toffoli gates and CZ gate\n",
    "#       to implement cccz gate, which will flip the\n",
    "#       sign of state |1111>\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2-4) control qubits;\n",
    "#             (5) target qubits;\n",
    "#             (6-7) auxiliary qubits.\n",
    "######################################################\n",
    "def cccz(circ, q1, q2, q3, q4, aux1, aux2):\n",
    "    # Apply Z-gate to a state controlled by 4 qubits\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    circ.ccx(q3, aux1, aux2)\n",
    "    circ.cz(aux2, q4)\n",
    "    # cleaning the aux bits\n",
    "    circ.ccx(q3, aux1, aux2)\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    return circ\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: cccz from Listing 4\n",
    "# Note: using the basic Toffoli gate to implement ccccx\n",
    "#       gate. It is used to switch the quantum states\n",
    "#       of |11110> and |11111>.\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2-5) control qubits;\n",
    "#             (6) target qubits;\n",
    "#             (7-8) auxiliary qubits.\n",
    "######################################################\n",
    "def ccccx(circ, q1, q2, q3, q4, q5, aux1, aux2):\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    circ.ccx(q3, q4, aux2)\n",
    "    circ.ccx(aux2, aux1, q5)\n",
    "    # cleaning the aux bits\n",
    "    circ.ccx(q3, q4, aux2)\n",
    "    circ.ccx(q1, q2, aux1)\n",
    "    return circ\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: neg_weight_gate from Listing 3\n",
    "# Note: adding NOT(X) gate before the qubits associated\n",
    "#       with 0 state. For example, if we want to flip \n",
    "#       the sign of |1101>, we add X gate for q2 before\n",
    "#       the cccz gate, as follows.\n",
    "#       --q3-----|---\n",
    "#       --q2----X|X--\n",
    "#       --q1-----|---\n",
    "#       --q0-----z---\n",
    "# Parameters: (1) quantum circuit; \n",
    "#             (2) all qubits, say q0-q3;\n",
    "#             (3) the auxiliary qubits used for cccz\n",
    "#             (4) states, say 1101\n",
    "######################################################\n",
    "def neg_weight_gate(circ,qubits,aux,state):\n",
    "    idx = 0\n",
    "    # The index of qubits are reversed in terms of states.\n",
    "    # As shown in the above example: we put X at q2 not the third position.\n",
    "    state = state[::-1]\n",
    "    for idx in range(len(state)):\n",
    "        if state[idx]=='0':\n",
    "            circ.x(qubits[idx])\n",
    "    cccz(circ,qubits[0],qubits[1],qubits[2],qubits[3],aux[0],aux[1])\n",
    "    for idx in range(len(state)):\n",
    "        if state[idx]=='0':\n",
    "            circ.x(qubits[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Using torch to load MNIST data\n",
    "######################################################\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Id: 0, Target: tensor([0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical Data: tensor([0.0902, 0.1882, 0.1059, 0.0039, 0.0745, 0.3216, 0.3608, 0.0314, 0.1176,\n",
      "        0.2392, 0.2902, 0.1882, 0.0275, 0.1333, 0.1647, 0.0863])\n",
      "Quantum Data: tensor([0.1229, 0.2565, 0.1443, 0.0053, 0.1015, 0.4381, 0.4916, 0.0427, 0.1603,\n",
      "        0.3259, 0.3954, 0.2565, 0.0374, 0.1817, 0.2244, 0.1175],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# T1: Downsample the image from 28*28 to 4*4\n",
    "# T2: Convert classical data to quantum data which \n",
    "#     can be encoded to the quantum states (amplitude)\n",
    "######################################################\n",
    "\n",
    "# Process data by hand, we can also integrate ToQuantumData into transform\n",
    "def data_pre_pro(img):\n",
    "    # Print original figure\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    # Print resized figure\n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    plt.show()\n",
    "    # Converting classical data to quantum data\n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_vector = ToQuantumData()\n",
    "    trans_to_matrix = ToQuantumMatrix()    \n",
    "    print(\"Classical Data: {}\".format(trans_to_tensor(im).flatten()))\n",
    "    print(\"Quantum Data: {}\".format(trans_to_vector(trans_to_tensor(im)).flatten()))\n",
    "    return trans_to_matrix(trans_to_tensor(im)),trans_to_vector(trans_to_tensor(im))\n",
    "\n",
    "# Use the first image from test loader as example\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Parameters of the trained model\n",
    "# The training procedure will be found in another repo\n",
    "# https://github.com/weiwenjiang/QuantumFlow\n",
    "######################################################\n",
    "\n",
    "# Model initialization\n",
    "weight_1_1 = torch.tensor([1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])\n",
    "\n",
    "weight_2_1 = torch.tensor([1.,  -1.])\n",
    "norm_flag_1 = True\n",
    "norm_para_1 = torch.tensor(0.3060)\n",
    "\n",
    "weight_2_2 = torch.tensor([-1.,  -1.])\n",
    "norm_flag_2 = False\n",
    "norm_para_2 = torch.tensor(0.6940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ┌────────┐                                  ░                »\n",
      "     in_qbit_0: ┤0       ├───────■──────────────────────■───░────────■───────»\n",
      "                │        │       │                      │   ░ ┌───┐  │       »\n",
      "     in_qbit_1: ┤1       ├───────■──────────────────────■───░─┤ X ├──■───────»\n",
      "                │  Input │       │                      │   ░ ├───┤  │       »\n",
      "     in_qbit_2: ┤2       ├───────┼────■───────■─────────┼───░─┤ X ├──┼────■──»\n",
      "                │        │┌───┐  │    │       │  ┌───┐  │   ░ └───┘  │    │  »\n",
      "     in_qbit_3: ┤3       ├┤ X ├──┼────┼───■───┼──┤ X ├──┼───░────────┼────┼──»\n",
      "                └────────┘└───┘┌─┴─┐  │   │   │  └───┘┌─┴─┐ ░      ┌─┴─┐  │  »\n",
      "    aux_qbit_0: ───────────────┤ X ├──■───┼───■───────┤ X ├─░──────┤ X ├──■──»\n",
      "                               └───┘┌─┴─┐ │ ┌─┴─┐     └───┘ ░      └───┘┌─┴─┐»\n",
      "    aux_qbit_1: ────────────────────┤ X ├─■─┤ X ├───────────░───────────┤ X ├»\n",
      "                                    └───┘   └───┘           ░           └───┘»\n",
      "hidden_qbits_0: ────────────────────────────────────────────░────────────────»\n",
      "                                                            ░                »\n",
      "         reg: 1/═════════════════════════════════════════════════════════════»\n",
      "                                                                             »\n",
      "«                                   ░                                   ░ ┌───┐»\n",
      "«     in_qbit_0: ──────────■────────░────────■─────────────────■────────░─┤ H ├»\n",
      "«                          │  ┌───┐ ░        │                 │        ░ ├───┤»\n",
      "«     in_qbit_1: ──────────■──┤ X ├─░────────■─────────────────■────────░─┤ H ├»\n",
      "«                          │  ├───┤ ░ ┌───┐  │                 │  ┌───┐ ░ ├───┤»\n",
      "«     in_qbit_2: ─────■────┼──┤ X ├─░─┤ X ├──┼────■───────■────┼──┤ X ├─░─┤ H ├»\n",
      "«                     │    │  └───┘ ░ └───┘  │    │       │    │  └───┘ ░ ├───┤»\n",
      "«     in_qbit_3: ─■───┼────┼────────░────────┼────┼───■───┼────┼────────░─┤ H ├»\n",
      "«                 │   │  ┌─┴─┐      ░      ┌─┴─┐  │   │   │  ┌─┴─┐      ░ └───┘»\n",
      "«    aux_qbit_0: ─┼───■──┤ X ├──────░──────┤ X ├──■───┼───■──┤ X ├──────░──────»\n",
      "«                 │ ┌─┴─┐└───┘      ░      └───┘┌─┴─┐ │ ┌─┴─┐└───┘      ░      »\n",
      "«    aux_qbit_1: ─■─┤ X ├───────────░───────────┤ X ├─■─┤ X ├───────────░──────»\n",
      "«                   └───┘           ░           └───┘   └───┘           ░      »\n",
      "«hidden_qbits_0: ───────────────────░───────────────────────────────────░──────»\n",
      "«                                   ░                                   ░      »\n",
      "«         reg: 1/══════════════════════════════════════════════════════════════»\n",
      "«                                                                              »\n",
      "«                ┌───┐                         \n",
      "«     in_qbit_0: ┤ X ├──■───────────────────■──\n",
      "«                ├───┤  │                   │  \n",
      "«     in_qbit_1: ┤ X ├──■───────────────────■──\n",
      "«                ├───┤  │                   │  \n",
      "«     in_qbit_2: ┤ X ├──┼────■─────────■────┼──\n",
      "«                ├───┤  │    │         │    │  \n",
      "«     in_qbit_3: ┤ X ├──┼────■─────────■────┼──\n",
      "«                └───┘┌─┴─┐  │         │  ┌─┴─┐\n",
      "«    aux_qbit_0: ─────┤ X ├──┼────■────┼──┤ X ├\n",
      "«                     └───┘┌─┴─┐  │  ┌─┴─┐└───┘\n",
      "«    aux_qbit_1: ──────────┤ X ├──■──┤ X ├─────\n",
      "«                          └───┘┌─┴─┐└┬─┬┘     \n",
      "«hidden_qbits_0: ───────────────┤ X ├─┤M├──────\n",
      "«                               └───┘ └╥┘      \n",
      "«         reg: 1/══════════════════════╩═══════\n",
      "«                                      0       \n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum circuit implementation\n",
    "######################################################\n",
    "\n",
    "# From Listing 2: creat the qubits to hold data\n",
    "inp = QuantumRegister(4,\"in_qbit\")\n",
    "circ = QuantumCircuit(inp)\n",
    "data_matrix = quantum_matrix\n",
    "circ.append(UnitaryGate(data_matrix, label=\"Input\"), inp[0:4])\n",
    "\n",
    "# From Listing 3: create auxiliary qubits\n",
    "aux = QuantumRegister(2,\"aux_qbit\")\n",
    "circ.add_register(aux)\n",
    "\n",
    "# From Listing 4: create output qubits for the first layer (hidden neurons)\n",
    "hidden_neurons = QuantumRegister(1,\"hidden_qbits\")\n",
    "circ.add_register(hidden_neurons)\n",
    "\n",
    "# Add classical register\n",
    "c_reg = ClassicalRegister(1,\"reg\")\n",
    "circ.add_register(c_reg)\n",
    "\n",
    "# From Listing 3: to multiply inputs and weights on quantum circuit\n",
    "if weight_1_1.sum()<0:\n",
    "    weight_1_1 = weight_1_1*-1\n",
    "idx = 0\n",
    "for idx in range(weight_1_1.flatten().size()[0]):\n",
    "    if weight_1_1[idx]==-1:\n",
    "        state = \"{0:b}\".format(idx).zfill(4)\n",
    "        neg_weight_gate(circ,inp,aux,state)\n",
    "        circ.barrier()\n",
    "    \n",
    "# From Listing 4: applying the quadratic function on the weighted sum\n",
    "circ.h(inp)\n",
    "circ.x(inp)\n",
    "ccccx(circ,inp[0],inp[1],inp[2],inp[3],hidden_neurons[0],aux[0],aux[1])\n",
    "\n",
    "# Measure output of the neuron to see the result, which is not necessary for multi-layer network\n",
    "circ.measure(hidden_neurons,c_reg)\n",
    "\n",
    "print(circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: job has successfully run\n",
      "[0.263262]\n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Quantum simulation\n",
    "######################################################\n",
    "\n",
    "# From Listing 6: execute the quantum circuit to obtain the results\n",
    "qc_shots=1000000\n",
    "counts = fire_ibmq(circ,qc_shots,True)\n",
    "(mycount,bits) = analyze(counts)\n",
    "class_prob=[]\n",
    "for b in range(bits):\n",
    "    class_prob.append(float(mycount[b])/qc_shots)\n",
    "print(class_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.2631, dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Do the same compuation in classical computing for\n",
    "# comparison.\n",
    "######################################################\n",
    "\n",
    "input_data = qantum_data.flatten()\n",
    "weight_neuron_1 = weight_1_1\n",
    "weighted_sum_neuron_1 = (input_data*weight_neuron_1).sum()\n",
    "result_neuron_1 = weighted_sum_neuron_1.pow(2)/len(weight_neuron_1)\n",
    "\n",
    "print([result_neuron_1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
