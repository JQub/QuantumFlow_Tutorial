{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import functools\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "interest_num = [3,6]\n",
    "ori_img_size = 28\n",
    "img_size = 4\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 1\n",
    "inference_batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "# Weiwen: modify the target classes starting from 0. Say, [3,6] -> [0,1]\n",
    "def modify_target(target):\n",
    "    for j in range(len(target)):\n",
    "        for idx in range(len(interest_num)):\n",
    "            if target[j] == interest_num[idx]:\n",
    "                target[j] = idx\n",
    "                break\n",
    "    new_target = torch.zeros(target.shape[0],2)\n",
    "    for i in range(target.shape[0]):        \n",
    "        if target[i].item() == 0:            \n",
    "            new_target[i] = torch.tensor([1,0]).clone()     \n",
    "        else:\n",
    "            new_target[i] = torch.tensor([0,1]).clone()\n",
    "               \n",
    "    return target,new_target\n",
    "\n",
    "# Weiwen: select sub-set from MNIST\n",
    "def select_num(dataset,interest_num):\n",
    "    labels = dataset.targets #get labels\n",
    "    labels = labels.numpy()\n",
    "    idx = {}\n",
    "    for num in interest_num:\n",
    "        idx[num] = np.where(labels == num)\n",
    "    fin_idx = idx[interest_num[0]]\n",
    "    for i in range(1,len(interest_num)):           \n",
    "        fin_idx = (np.concatenate((fin_idx[0],idx[interest_num[i]][0])),)\n",
    "    \n",
    "    fin_idx = fin_idx[0]    \n",
    "    dataset.targets = labels[fin_idx]\n",
    "    dataset.data = dataset.data[fin_idx]\n",
    "    dataset.targets,_ = modify_target(dataset.targets)\n",
    "    return dataset\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum data\n",
    "######################################################\n",
    "class ToQuantumData(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        output_data = output_matrix[:, 0].view(1, img_size,img_size)\n",
    "        return output_data\n",
    "\n",
    "################ Weiwen on 12-30-2020 ################\n",
    "# Function: ToQuantumData from Listing 1\n",
    "# Note: Coverting classical data to quantum matrix\n",
    "######################################################\n",
    "class ToQuantumMatrix(object):\n",
    "    def __call__(self, tensor):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        data = tensor.to(device)\n",
    "        input_vec = data.view(-1)\n",
    "        vec_len = input_vec.size()[0]\n",
    "        input_matrix = torch.zeros(vec_len, vec_len)\n",
    "        input_matrix[0] = input_vec\n",
    "        input_matrix = np.float64(input_matrix.transpose(0,1))\n",
    "        u, s, v = np.linalg.svd(input_matrix)\n",
    "        output_matrix = torch.tensor(np.dot(u, v))\n",
    "        return output_matrix                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Using torch to load MNIST data\n",
    "######################################################\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Path to MNIST Dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "train_data = select_num(train_data,interest_num)\n",
    "test_data =  select_num(test_data,interest_num)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Id: 0, Target: tensor([0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical Data: tensor([0.0039, 0.2118, 0.2941, 0.0275, 0.0039, 0.2784, 0.5961, 0.0667, 0.0863,\n",
      "        0.3176, 0.5216, 0.0588, 0.1137, 0.3608, 0.1725, 0.0039])\n",
      "Quantum Data: tensor([0.0037, 0.1996, 0.2772, 0.0259, 0.0037, 0.2624, 0.5617, 0.0628, 0.0813,\n",
      "        0.2993, 0.4915, 0.0554, 0.1072, 0.3400, 0.1626, 0.0037],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# T1: Downsample the image from 28*28 to 4*4\n",
    "# T2: Convert classical data to quantum data which \n",
    "#     can be encoded to the quantum states (amplitude)\n",
    "######################################################\n",
    "\n",
    "# Process data by hand, we can also integrate ToQuantumData into transform\n",
    "def data_pre_pro(img):\n",
    "    # Print original figure\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "    plt.show()\n",
    "    # Print resized figure\n",
    "    image = np.asarray(npimg[0] * 255, np.uint8)    \n",
    "    im = Image.fromarray(image,mode=\"L\")\n",
    "    im = im.resize((4,4),Image.BILINEAR)    \n",
    "    plt.imshow(im,cmap='gray',)\n",
    "    plt.show()\n",
    "    # Converting classical data to quantum data\n",
    "    trans_to_tensor = transforms.ToTensor()\n",
    "    trans_to_vector = ToQuantumData()\n",
    "    trans_to_matrix = ToQuantumMatrix()    \n",
    "    print(\"Classical Data: {}\".format(trans_to_tensor(im).flatten()))\n",
    "    print(\"Quantum Data: {}\".format(trans_to_vector(trans_to_tensor(im)).flatten()))\n",
    "    return trans_to_matrix(trans_to_tensor(im)),trans_to_vector(trans_to_tensor(im))\n",
    "\n",
    "# Use the first image from test loader as example\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\n",
    "    print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\n",
    "    quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ┌────────┐\n",
      "in_qbit_0: ┤0       ├\n",
      "           │        │\n",
      "in_qbit_1: ┤1       ├\n",
      "           │  Input │\n",
      "in_qbit_2: ┤2       ├\n",
      "           │        │\n",
      "in_qbit_3: ┤3       ├\n",
      "           └────────┘\n",
      "Data to be encoded: \n",
      " tensor([[[0.0037, 0.1996, 0.2772, 0.0259],\n",
      "         [0.0037, 0.2624, 0.5617, 0.0628],\n",
      "         [0.0813, 0.2993, 0.4915, 0.0554],\n",
      "         [0.1072, 0.3400, 0.1626, 0.0037]]], dtype=torch.float64)\n",
      "\n",
      "Data read from the circuit: \n",
      " [0.00369542+0.j 0.19955294+0.j 0.27715687+0.j 0.02586797+0.j\n",
      " 0.00369542+0.j 0.26237517+0.j 0.56170458+0.j 0.06282222+0.j\n",
      " 0.08129935+0.j 0.29932941+0.j 0.49149152+0.j 0.05543137+0.j\n",
      " 0.10716732+0.j 0.33997908+0.j 0.16259869+0.j 0.00369542+0.j]\n"
     ]
    }
   ],
   "source": [
    "################ Weiwen on 12-30-2020 ################\n",
    "# Do quantum state preparation and compare it with\n",
    "# the original data\n",
    "######################################################\n",
    "\n",
    "# Quantum-State Preparation in IBM Qiskit\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.extensions import XGate, UnitaryGate\n",
    "from qiskit import Aer, execute\n",
    "import qiskit\n",
    "# Input: a 4*4 matrix (data) holding 16 input data\n",
    "inp = QuantumRegister(4,\"in_qbit\")\n",
    "circ = QuantumCircuit(inp)\n",
    "data_matrix = quantum_matrix\n",
    "circ.append(UnitaryGate(data_matrix, label=\"Input\"), inp[0:4])\n",
    "print(circ)\n",
    "# Using StatevectorSimulator from the Aer provider\n",
    "simulator = Aer.get_backend('statevector_simulator')\n",
    "result = execute(circ, simulator).result()\n",
    "statevector = result.get_statevector(circ)\n",
    "\n",
    "print(\"Data to be encoded: \\n {}\\n\".format(qantum_data))\n",
    "print(\"Data read from the circuit: \\n {}\".format(statevector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
